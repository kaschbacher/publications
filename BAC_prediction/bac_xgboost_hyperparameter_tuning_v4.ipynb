{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost for BACtrack Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import itertools\n",
    "import sys\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# Might need to go before xgboost imports\n",
    "import importlib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score, auc, roc_curve, \\\n",
    "    confusion_matrix, classification_report\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config Application.log_level=\"INFO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 20:01:42,795 | INFO : Hello world!\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s | %(levelname)s : %(message)s',\n",
    "                     level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "logging.info('Hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GLOBAL VARIABLES AND SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secure-copy updated data to server: \n",
    "# scp $LOCAL_PATH kaschbacher@tisoncluster.ucsf.edu:$SERVER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data'\n",
    "FIGURE_FOLDER = 'figures'\n",
    "#FILENAME = 'bac_2018-11-27.h5'\n",
    "FILENAME = 'bac_2019-06-07.parquet'#'bac_2019-03-26.parquet'\n",
    "PATH = '/'.join([DATA_FOLDER, FILENAME])\n",
    "TODAY = str(dt.date.today())\n",
    "MISSING_VALUE = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 9\n",
    "TRAIN_P = .70\n",
    "DEV_P = .10\n",
    "\n",
    "TEST_P = 1 - TRAIN_P - DEV_P\n",
    "split_percents = [TRAIN_P, DEV_P, TEST_P]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BOOSTING_PARAMS = {\n",
    "    'silent':1,\n",
    "    'learning_rate':.3,\n",
    "    'max_depth':6,\n",
    "    'min_child_weight':1,# default=1, larger=more conservative; building process will give up partitioning \n",
    "    'subsample':0.80,\n",
    "    'colsample_bytree':0.80,\n",
    "    'objective':'binary:logistic',#'objective':'binary:logistic' or 'reg:linear'\n",
    "    'num_boost_round': 10,\n",
    "    #'eval_metric':'auc',\n",
    "    'random_state':7,\n",
    "    'lambda':1,# default=1, L2 (ridge); higher values = more conservative\n",
    "    'alpha':0,# default=0, L1 (lasso); higher values = more conservative\n",
    "    'gamma':0,# [default=0, alias: min_split_loss] - Larger=more conservative. Minimum loss reduction required to make a further partition on a leaf node of the tree\n",
    "    'scale_pos_weight':1# default=1, reset later based on class distribution\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starts with defaults, but can change\n",
    "boosting_params = DEFAULT_BOOSTING_PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Parameters for Grid Search\n",
    "def get_gs_params(params):\n",
    "    gs_params = {\n",
    "        'learning_rate': params['learning_rate'], \n",
    "        'num_boost_round': params['num_boost_round'],\n",
    "        #'n_estimators': best_n_estimators, \n",
    "        'max_depth': params['max_depth'],\n",
    "        'min_child_weight': params['min_child_weight'], \n",
    "        'gamma': params['gamma'], \n",
    "        'subsample': params['subsample'], \n",
    "        'colsample_bytree': params['colsample_bytree'], \n",
    "        'return_train_score': True,\n",
    "        'objective': 'binary:logistic', \n",
    "        #'n_jobs': 4,# -1 --> make use of all the cores in your system; but supposedly could also slow things \n",
    "        'scale_pos_weight':params['scale_pos_weight'], \n",
    "        'seed':7\n",
    "    }\n",
    "    return gs_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_params = {\n",
    "    'figure.figsize':(5,5),\n",
    "    'figure.titlesize':20,\n",
    "    'xtick.labelsize': 13,\n",
    "    'ytick.labelsize': 13,\n",
    "    'axes.labelsize': 18\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    df = pq.read_table(path, use_threads=4).to_pandas()\n",
    "    names = df.columns.tolist()\n",
    "    data = df.values\n",
    "    return names, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Randomly Shuffle the rows\n",
    "--- so that there is no systematic association of date with train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_rows(data, SEED):\n",
    "    # shuffles rows of an np-array, w/ seed, order will always be replicable\n",
    "    np.random.seed(seed=SEED)\n",
    "    np.random.shuffle(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option to partition by observation --> train/dev/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_by_observation(split_percents, data, idx_uid):\n",
    "    train_per, dev_per, test_per = split_percents\n",
    "    m = data.shape[0]\n",
    "    train, dev, test = np.split(data, [int(m*train_per), int(m*(train_per+dev_per))]) \n",
    "    print ('train shape: {}, dev shape: {}, test shape: {}'.format(train.shape, dev.shape, test.shape))\n",
    "    assert train.shape[0] + dev.shape[0] + test.shape[0] == data.shape[0]\n",
    "    \n",
    "    # Assumes y or target outcome is the first column, and that all other columns will be included in X\n",
    "    # Omit user_id in column 1\n",
    "    if idx_uid!=1: print ('Error: Expected user id in column 1, in function partition by observation')\n",
    "    partitions = {}\n",
    "    partitions['X_train'] = train[:,2:]\n",
    "    partitions['y_train'] = train[:,0]\n",
    "    partitions['X_dev'] = dev[:,2:]\n",
    "    partitions['y_dev'] = dev[:,0]\n",
    "    partitions['X_test'] = test[:,2:]\n",
    "    partitions['y_test'] = test[:,0]\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option to Partition by User\n",
    "<p> -- dev and test set will not share any users with train set. No learning possible about individual users </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_uids(data):\n",
    "    # Get unique user ids\n",
    "    user_ids = np.unique(data[:,1])\n",
    "    print ('Number of unique users: {}'.format(user_ids.shape[0]))\n",
    "    np.random.shuffle(user_ids)\n",
    "    return user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_users(users, split_percents):\n",
    "    train_per, dev_per, test_per = split_percents\n",
    "    s = len(users)\n",
    "    arys = np.split(users, [int(train_per*s), int((train_per+dev_per)*s)])\n",
    "    return arys[0], arys[1], arys[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idx(uuids, idx_uid):\n",
    "    # given a list of user ids, find the indices in the data np-ary that represent observations from these users\n",
    "    idx = []\n",
    "    for ui in uuids:\n",
    "        temp = np.where(data[:, idx_uid]==ui)[0]\n",
    "        idx = np.append(idx, temp, axis=0).astype(int)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_by_user(split_percents, data, idx_uid):\n",
    "    # Get arrays of user_ids that partition up the train, dev, test\n",
    "    uuids = get_unique_uids(data)# returns a randomly shuffled array of unique user ids\n",
    "    train_ui, dev_ui, test_ui = partition_users(uuids, split_percents)\n",
    "    assert len(uuids) == train_ui.shape[0] + dev_ui.shape[0] + test_ui.shape[0]\n",
    "\n",
    "    # Get the indices for the observations belonging to a given set of user_ids\n",
    "\n",
    "    partitions={}\n",
    "    segments = {'train': train_ui, 'dev': dev_ui, 'test': test_ui}\n",
    "    for k, uuids in segments.items():\n",
    "        print ('Running segment: {}...'.format(k))\n",
    "        %time\n",
    "        idx = get_idx(uuids, idx_uid)\n",
    "        idx = np.sort(idx)\n",
    "        partitions['X_'+k]=data[idx, 2:]\n",
    "        partitions['y_'+k]=data[idx, 0]\n",
    "    print ('train shape: {}, dev shape: {}, test shape: {}'.format(partitions['X_train'].shape, partitions['X_dev'].shape, partitions['X_test'].shape))\n",
    "        \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Package Data Matrices for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def package_data (partitions, names, idx_uid):\n",
    "    # Assign data - (Note: must dropna first, otherwise missing=-999 throws an error because NaNs also still exist)\n",
    "    print (\"\\nSetting up data-matrices for Gradient Boosted Classification Tree with Outcome: {}...\\n\".format(names[0]))\n",
    "\n",
    "    names = [str(name) for name in names]# convert from byte to string\n",
    "    del names[idx_uid]# Omit user_id at idx, 1\n",
    "    partitions['names']=names\n",
    "    partitions['dtrain'] = xgb.DMatrix(data=partitions['X_train'], label=partitions['y_train'], \n",
    "                                       feature_names=names[1:], missing=MISSING_VALUE)\n",
    "    partitions['ddev'] = xgb.DMatrix(data=partitions['X_dev'], label=partitions['y_dev'], \n",
    "                                     feature_names=names[1:], missing=MISSING_VALUE)\n",
    "    partitions['dtest'] = xgb.DMatrix(data=partitions['X_test'], label=partitions['y_test'], \n",
    "                                      feature_names=names[1:], missing=MISSING_VALUE)\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_balance_weight(y_train):\n",
    "\n",
    "    pos = np.sum(y_train, axis=0, dtype=int)\n",
    "    neg = y_train.shape[0]-pos\n",
    "    print ('\\n{} positive cases and {} negative cases'.format(pos, neg))\n",
    "\n",
    "    scale_pos_weight = round(neg/pos, 2)# 2.38 for the BACtrack dataset\n",
    "    print ('Scale Weight for balanced classes would be: {}'.format(scale_pos_weight))\n",
    "    return scale_pos_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training/Fitting the Model\n",
    "--- fit vs train -- https://datascience.stackexchange.com/questions/17282/xgbregressor-vs-xgboost-train-huge-speed-difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(dtrain, ddev, boosting_params):\n",
    "    # # Training a Model\n",
    "    # # -- xgboost.train will ignore parameter n_estimators, while xgboost.XGBRegressor accepts. \n",
    "    # # -- In xgboost.train, boosting iterations (i.e. n_estimators) is controlled by num_boost_round(default: 10)\n",
    "    # # -- the learning_rate (eta) and num_boost_rounds are instrisincally connected.  \n",
    "    # # -- Slower learning rates will typically require more rounds\n",
    "\n",
    "    # if num_boost_round not explicitly given as kwarg, it will be overridden by default of 10, which can be seen in eval printing\n",
    "    watchlist = [(ddev, 'dev'), (dtrain, 'train')]\n",
    "    %time\n",
    "    model = xgb.train(params=boosting_params, dtrain=dtrain, evals=watchlist, verbose_eval=True,\n",
    "                      num_boost_round=boosting_params['num_boost_round'])# try predictor='gpu_predictor'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make & Evaluate Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, d_true):\n",
    "    # d_true is the xgboost prepared dataset corresponding to test or dev (per needs); includes X and y and names\n",
    "    y_proba = model.predict(d_true)\n",
    "    y_pred = [round(value) for value in y_proba]# Use to get 0 vs 1?\n",
    "    return y_pred, y_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred, y_proba):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_proba, average='micro', max_fpr=None)#sample_weight=scale_pos_weight, \n",
    "    print ('Accuracy: {:02.2f}%'.format(accuracy*100.))\n",
    "    print ('ROC AUC: {:02.2f}%'.format(roc_auc*100.))\n",
    "    return accuracy, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\\n\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Report (w/ Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_report(figure_params, y_test, y_pred, target_names):\n",
    "    \n",
    "    # # Plot Confusion Matrix for Classification - http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    plt.rcParams.update(figure_params)\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, ['low BAC','high BAC'], normalize=True)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.show()\n",
    "    fig.savefig('/'.join( \\\n",
    "        [FIGURE_FOLDER,'/cm/Normalized_Confusion_Matrix_BAC_Classification_{}.png'.format(TODAY)]), \\\n",
    "        bbox_inches='tight')\n",
    "\n",
    "    # Classification Report\n",
    "    #print ('\\nAccuracy: {:02.2f}%\\n'.format(accuracy*100.))\n",
    "    print (classification_report(y_test, y_pred, target_names=target_names),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC(y_test, y_pred_proba):\n",
    "    # y_test can also be y_dev, depending on context\n",
    "    \n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # Calculate x and y for ROC-curve\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    #print (fpr.shape, tpr.shape, roc_auc)# DEBUG\n",
    "\n",
    "    #Plot of a ROC curve for a specific class\n",
    "    plt.rcParams.update(figure_params)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=2, label='ROC curve (area = {:0.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built-in Feature Importance Graph:  \n",
    "--- importance_type='weight' matches above.  'cover' provides quite different results, which may be of interest to report in paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_importances(model):  \n",
    "    \n",
    "    # -- http://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
    "    # weight” is the number of times a feature appears in a tree “gain” is the average gain of splits which use the feature...\n",
    "    # “cover” is the average coverage of splits which use the feature, where coverage is defined as the number of samples affected by the split\n",
    "    plt.rcParams['figure.figsize']=(14,18)\n",
    "    xgb.plot_importance(model, importance_type='weight')\n",
    "    plt.title('Feature Importance (Weight)', fontsize=20)\n",
    "    plt.show()\n",
    "    plt.savefig('/'.join([FIGURE_FOLDER,'fi/feature_importance_{}.png'.format(TODAY)]), \\\n",
    "                bbox_inches='tight')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(973264, 92) \n",
      "\n",
      "['bac_clinical', 'user_id', 'bac_guess']\n",
      "CPU times: user 4.22 s, sys: 3.78 s, total: 8 s\n",
      "Wall time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load Data\n",
    "names, data = load_data(PATH)\n",
    "print (data.shape, '\\n')# QA\n",
    "print (names[:3])# Ensure that bac_clinical (or the outcome) is the first column!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.03 s, sys: 23 ms, total: 4.05 s\n",
      "Wall time: 4.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  2.79300000e+03,  0.00000000e+00, ...,\n",
       "                    nan,             nan,             nan],\n",
       "       [ 1.00000000e+00,  2.99050000e+04,  5.00000007e-02, ...,\n",
       "         2.19900000e+03,  5.60000000e+00,  1.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.73040000e+04,  3.99999991e-02, ...,\n",
       "        -4.80000000e+01, -1.00000000e+00,  1.00000000e+00],\n",
       "       ...,\n",
       "       [ 1.00000000e+00,  4.34900000e+03,  2.99999993e-02, ...,\n",
       "                    nan,             nan,             nan],\n",
       "       [ 1.00000000e+00,  2.10500000e+03,  2.99999993e-02, ...,\n",
       "                    nan,             nan,             nan],\n",
       "       [ 1.00000000e+00,  1.54300000e+03,  0.00000000e+00, ...,\n",
       "         1.17000000e+02,  2.10000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Partition randomly\n",
    "shuffle_rows(data, SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition data in 1 of 2 ways - (by randomly assigning either observations or users to the train/dev/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 33460\n",
      "Running segment: train...\n",
      "CPU times: user 6 µs, sys: 2 µs, total: 8 µs\n",
      "Wall time: 39.8 µs\n",
      "Running segment: dev...\n",
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n",
      "Running segment: test...\n",
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 9.3 µs\n",
      "\n",
      "Setting up data-matrices for Gradient Boosted Classification Tree with Outcome: bac_clinical...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm what column user_id is in\n",
    "idx_uid = 1\n",
    "assert names[idx_uid]=='user_id'\n",
    "    \n",
    "partitions = partition_by_user(split_percents, data, idx_uid)\n",
    "#partitions = partition_by_observation(split_percents, data, idx_uid)\n",
    "\n",
    "# Package data for XGboost\n",
    "partitions = package_data(partitions, names, idx_uid)# Adds names + dtrain, ddev, dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balancing the Classes/ Determining Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(boosting_params, partitions):\n",
    "    prior_scale_pos_weight = boosting_params['scale_pos_weight']\n",
    "    # Reset scale weight in boosting params and in the grid search params both\n",
    "    boosting_params['scale_pos_weight'] = get_balance_weight(partitions['y_train'])\n",
    "    gs_params = get_gs_params(boosting_params)\n",
    "    print ('\\nResetting positive scale weight from {} to {}...\\n'.format(prior_scale_pos_weight, boosting_params['scale_pos_weight']))\n",
    "    return gs_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default Model for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_wwo_balancing(boosting_params, partitions):\n",
    "    \n",
    "    # Assumption is that boosting_params starts out at the default, and then can be altered throughout the tuning process\n",
    "    if boosting_params != DEFAULT_BOOSTING_PARAMS:\n",
    "        print ('Resetting boosting params to be equal to DEFAULT\\n')\n",
    "        boosting_params = DEFAULT_BOOSTING_PARAMS\n",
    "    # Assumes we start with no scale weighting, and compare that to weighting inversely to case prevalence in the training set\n",
    "    if boosting_params['scale_pos_weight'] != 1:\n",
    "        print ('Converting the scale weight for boosting params back to 1 for the first run...\\n')\n",
    "        boosting_params['scale_pos_weight'] = 1\n",
    "    \n",
    "    # Fit & Evaluate model twice: 1) Unbalanced, 2) Balanced\n",
    "    for i in range(0,2):\n",
    "        if i>0: \n",
    "            print ('-'*60,'\\n')\n",
    "            balance_classes(boosting_params, partitions)\n",
    "            \n",
    "        # Fit Model\n",
    "        print ('Run {}, Scale weight = {:0.2f}'.format(i, boosting_params['scale_pos_weight']))\n",
    "        model= fit_model(partitions['dtrain'], partitions['ddev'], boosting_params)\n",
    "\n",
    "        # Predict/ Evaluate in Dev set\n",
    "        y_true = partitions['y_dev']; d_true = partitions['ddev']\n",
    "        y_pred, y_proba = predict(model, d_true)\n",
    "        accuracy, roc = evaluate_model(y_true, y_pred, y_proba)\n",
    "\n",
    "        # Get Results & Figures\n",
    "        plot_ROC(y_true, y_proba)\n",
    "        full_report(figure_params, y_true, y_pred, ['bac <.08', 'bac >=.08'])\n",
    "        #graph_importances(model) \n",
    "        \n",
    "#base_model_wwo_balancing(boosting_params, partitions)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Cross-Validated XGBoost to determine the optimal number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# EVALUATE LEARNING RATE AND MAX_DEPTH TOGETHER\n",
    "# For learning_rate=1 & max_depth=6 --> optimal number of trees=30\n",
    "boosting_params['learning_rate']= .01\n",
    "boosting_params['max_depth']= 6\n",
    "boosting_params['nthread']=-1\n",
    "boosting_params['num_boost_round']= 500\n",
    "boosting_params['verbose']=2\n",
    "# watchlist = [(partitions['ddev'], 'dev'), (partitions['dtrain'], 'train')]\n",
    "# boosting_params['evals']=watchlist\n",
    "\n",
    "print ('Boosting Params...\\n')\n",
    "for k, p in boosting_params.items():\n",
    "    print (k,p)\n",
    "print ('\\n')\n",
    "\n",
    "cvresult = xgb.cv(boosting_params, partitions['dtrain'], num_boost_round=boosting_params['num_boost_round'], \\\n",
    "                 nfold=3, early_stopping_rounds=10, verbose_eval=True, \\\n",
    "                 seed=7, metrics='auc')# metrics=['auc','mae','map']\n",
    "\n",
    "best_n_estimators = cvresult.shape[0]\n",
    "print ('\\nThe optimal number of trees is {}\\n'.format(best_n_estimators))\n",
    "# optimal trees was 52 with learning rate of 1 and early_stopping=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = np.where(cvresult.iloc[:,2]==cvresult.iloc[:,2].max())[0][0]\n",
    "print ('Best AUC in test set: {:0.4f} with {} trees or n_estimators'.format(cvresult.iloc[best_idx,2], best_idx+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset the number of Estimators (Trees) to match CV outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_params['num_boost_round']=best_n_estimators\n",
    "gs_params['num_boost_round']=best_n_estimators\n",
    "\n",
    "print (boosting_params)\n",
    "today = dt.date.today()\n",
    "print (today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth': list(np.arange(5, 8, 1)),\n",
    " 'min_child_weight': list(np.arange(1, 21, 10))#[ 1  6 11 16 21]\n",
    "}# 'alpha': [0, 1, 3]\n",
    "\n",
    "boosting_params['learning_rate']= .3\n",
    "boosting_params['num_boost_round']= 80\n",
    "boosting_params['pos_scale_weight']= get_balance_weight(partitions['y_train'])\n",
    "\n",
    "# Prints out in tmux terminal (not sure why...)\n",
    "gs_params = get_gs_params(boosting_params)\n",
    "print ('\\n\\nGrid Search parameters...\\n','-'*20,'\\n')\n",
    "for k, gsp in gs_params.items():\n",
    "    print (k, gsp)\n",
    "print ('\\n\\n')\n",
    "print (param_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# # Send logging to a file\n",
    "today = dt.date.today()\n",
    "#sys.stdout = open('xgboost_output_{}.txt'.format(today), 'w')\n",
    "\n",
    "# May get an Unpickling Error/ Broken Process if using custom score with multiprocessing/n_jobs # scoring='roc_auc', \n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(gs_params), \\\n",
    "                        param_grid = param_test1, \\\n",
    "                       verbose=3, \\\n",
    "                        n_jobs=1, iid=False, cv=3, refit=True)#return_train_score=True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env LOKY_PICKLER='cloudpickle' \n",
    "import multiprocessing\n",
    "#multiprocessing.set_start_method('forkserver', force=True)\n",
    "\n",
    "try:\n",
    "    multiprocessing.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsearch1.fit(partitions['X_train'], partitions['y_train'], eval_metric='auc', verbose=True, \\\n",
    "            eval_set=[(partitions['X_dev'], partitions['y_dev'])], early_stopping_rounds=10)\n",
    "# # Logging output to file\n",
    "#sys.stdout = sys.__stdout__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRINT BEST VALUES\n",
    "# Note: The best score from GridSearchCV is biased. :( If you gridsearch best params, you will overfit in terms of AUC\n",
    "print ('Best Hyperparameters: ', gsearch1.best_params_)\n",
    "print ('Best Score: {:02f}'.format(gsearch1.best_score_))\n",
    "print ('Best Estimator: ',gsearch1.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset Parameters to Best Values (from GridSearch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_params = list(gsearch1.best_params_.keys())\n",
    "for k, v in gsearch1.best_params_.items():\n",
    "    print (k,v)\n",
    "    boosting_params[k]=v  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (boosting_params)\n",
    "print (DEFAULT_BOOSTING_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(gsearch1.cv_results_).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boosting_params['alpha']=1\n",
    "# boosting_params['lambda']=10\n",
    "# print (boosting_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model - evaluates in the test set\n",
    "boosting_params['learning_rate']= .03\n",
    "boosting_params['max_depth']=8\n",
    "boosting_params['nthread']=-1\n",
    "boosting_params['num_boost_round']= 500\n",
    "boosting_params['verbose']=2\n",
    "balance_classes(boosting_params, partitions)\n",
    "\n",
    "\n",
    "print ('Boosting Params...\\n')\n",
    "for k, p in boosting_params.items():\n",
    "    print (k,p)\n",
    "print ('\\n')\n",
    "\n",
    "# error readout corresponds to 1-accuracy\n",
    "model= fit_model(partitions['dtrain'], partitions['ddev'], boosting_params)\n",
    "print ('\\n', boosting_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions in the TEST set\n",
    "y_pred, y_proba = predict(model, partitions['dtest'])\n",
    "accuracy, roc_auc = evaluate_model(partitions['y_test'], y_pred, y_proba)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "target_names = ['bac <.08', 'bac >=.08']\n",
    "full_report(figure_params, partitions['y_test'], y_pred, target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC-AUC\n",
    "--- https://www.kaggle.com/jeremy123w/xgboost-with-roc-curve\n",
    "--- # # http://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(partitions['y_test'], y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_importances(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save MODEL object - pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"bac_final.pickle.dat\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (DEFAULT_BOOSTING_PARAMS)\n",
    "print (boosting_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Try to save to Kirstin's local\n",
    "\n",
    "# LOCAL_FIGURE_FOLDER = '/Users/KAschbacher/Desktop/eheart/analysis/BAC/figures/server'\n",
    "# plt.savefig('/'.join([LOCAL_FIGURE_FOLDER,'feature_importance_{}.png'.format(TODAY)]), \\\n",
    "#             bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
